{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚åõ Procesando 2020...\n",
      "‚åõ Procesando 2021...\n",
      "‚åõ Procesando 2022...\n",
      "‚åõ Procesando 2023...\n",
      "‚åõ Procesando 2024...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Configuraci√≥n de salida\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "def procesar_ano(df, ano):\n",
    "    # Diccionario de mapeo basado en tus listas\n",
    "    # Nota: He a√±adido 'ANYO' porque as√≠ viene en tus archivos\n",
    "    mapeo = {\n",
    "            'ANYO': 'ANIO',\n",
    "            'COD_PROVINCIA': 'PROVINCIA',\n",
    "            'TIPO_VIA': 'TIPO_VIA_NOMBRE',\n",
    "            'TIPO_ACCIDENTE': 'TIPO_ACCIDENTE_NOMBRE',\n",
    "            'CONDICION_METEO': 'CONDICION_METEO', \n",
    "            'CARRETERA': 'CARRETERA'\n",
    "        }\n",
    "    df = df.rename(columns=mapeo)\n",
    "    \n",
    "    # 2. Rellenar nulos para las nuevas columnas de texto (Evita errores en el modelo)\n",
    "    for col in ['CONDICION_METEO', 'CARRETERA', 'DIA_SEMANA', 'CONDICION_ILUMINACION']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"DESCONOCIDO\")\n",
    "    # Columnas de fallecidos que me pasaste (exactas)\n",
    "    fallecidos_cols = [\n",
    "        'TOT_PEAT_MU24H', 'TOT_BICI_MU24H', 'TOT_CICLO_MU24H', 'TOT_MOTO_MU24H',\n",
    "        'TOT_TUR_MU24H', 'TOT_FURG_MU24H', 'TOT_CAM_MENOS3500_MU24H', \n",
    "        'TOT_CAM_MAS3500_MU24H', 'TOTAL_MU24H'\n",
    "    ]\n",
    "\n",
    "    # Asegurar que existan y no tengan nulos\n",
    "    for col in fallecidos_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # L√≥gica de unificaci√≥n para las gr√°ficas\n",
    "    df['MUERTOS_MOTO'] = df['TOT_CICLO_MU24H'] + df['TOT_MOTO_MU24H']\n",
    "    df['MUERTOS_COCHE'] = df['TOT_TUR_MU24H']\n",
    "    df['MUERTOS_BICI'] = df['TOT_BICI_MU24H']\n",
    "    \n",
    "    # Variable objetivo para el modelo y gr√°ficas\n",
    "    df['ES_MORTAL'] = (df['TOTAL_MU24H'] > 0).astype(int)\n",
    "    df['ANIO'] = ano # Forzamos el a√±o del archivo\n",
    "\n",
    "    # Selecci√≥n final de columnas para los JSON\n",
    "    cols_web = [\n",
    "        'ANIO', 'HORA', 'MES', 'DIA_SEMANA', 'PROVINCIA', \n",
    "        'TIPO_VIA_NOMBRE', 'TIPO_ACCIDENTE_NOMBRE', \n",
    "        'CONDICION_METEO', 'CARRETERA', 'CONDICION_ILUMINACION',\n",
    "        'MUERTOS_MOTO', 'MUERTOS_COCHE', 'MUERTOS_BICI', \n",
    "        'ES_MORTAL', 'TOTAL_MU24H' # A√±adimos TOTAL_MU24H para el JSON de carreteras\n",
    "    ]\n",
    "    \n",
    "    # Solo devolvemos las que existan para evitar KeyErrors\n",
    "    existentes = [c for c in cols_web if c in df.columns]\n",
    "    return df[existentes]\n",
    "\n",
    "# --- CARGA Y UNIFICACI√ìN ---\n",
    "\n",
    "archivos = {\n",
    "    2020: '../data/raw/acc_2020.xlsx', \n",
    "    2021: '../data/raw/acc_2021.xlsx', \n",
    "    2022: '../data/raw/acc_2022.xlsx', \n",
    "    2023: '../data/raw/acc_2023.xlsx',\n",
    "    2024: '../data/raw/acc_2024.xlsx'\n",
    "}\n",
    "\n",
    "datasets = []\n",
    "for ano, path in archivos.items():\n",
    "    print(f\"‚åõ Procesando {ano}...\")\n",
    "    temp_df = pd.read_excel(path, engine='openpyxl')\n",
    "    datasets.append(procesar_ano(temp_df, ano))\n",
    "\n",
    "df_historico = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# # --- EXPORTACI√ìN JSON ---\n",
    "\n",
    "# # 1. Evoluci√≥n (Barras)\n",
    "# df_historico.groupby('ANIO').agg({\n",
    "#     'MUERTOS_MOTO': 'sum', 'MUERTOS_COCHE': 'sum', \n",
    "#     'MUERTOS_BICI': 'sum', 'ES_MORTAL': 'count'\n",
    "# }).reset_index().to_json('../data/processed/stats_evolucion.json', orient='records')\n",
    "\n",
    "# # 2. Hora (L√≠nea)\n",
    "# df_historico.groupby('HORA')['ES_MORTAL'].mean().reset_index().to_json('../data/processed/prob_mortalidad_hora.json', orient='records')\n",
    "\n",
    "# print(\"‚úÖ Archivos JSON generados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_historico' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. Riesgo por Meteorolog√≠a\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf_historico\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mCONDICION_METEO\u001b[39m\u001b[33m'\u001b[39m).agg(\n\u001b[32m      3\u001b[39m     Total_Accidentes=(\u001b[33m'\u001b[39m\u001b[33mES_MORTAL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      4\u001b[39m     Probabilidad_Mortal=(\u001b[33m'\u001b[39m\u001b[33mES_MORTAL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m ).reset_index().to_json(\u001b[33m'\u001b[39m\u001b[33m../data/processed/stats_riesgo_meteo.json\u001b[39m\u001b[33m'\u001b[39m, orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 4. Top 20 Carreteras (Puntos Negros)\u001b[39;00m\n\u001b[32m      8\u001b[39m df_historico.groupby(\u001b[33m'\u001b[39m\u001b[33mCARRETERA\u001b[39m\u001b[33m'\u001b[39m).agg(\n\u001b[32m      9\u001b[39m     Total_Accidentes=(\u001b[33m'\u001b[39m\u001b[33mES_MORTAL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     Total_Muertos=(\u001b[33m'\u001b[39m\u001b[33mTOTAL_MU24H\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     11\u001b[39m     Riesgo_Tramo=(\u001b[33m'\u001b[39m\u001b[33mES_MORTAL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m ).reset_index().sort_values(by=\u001b[33m'\u001b[39m\u001b[33mTotal_Accidentes\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m20\u001b[39m).to_json(\u001b[33m'\u001b[39m\u001b[33m../data/processed/stats_riesgo_carreteras.json\u001b[39m\u001b[33m'\u001b[39m, orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_historico' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Riesgo por Meteorolog√≠a\n",
    "df_historico.groupby('CONDICION_METEO').agg(\n",
    "    Total_Accidentes=('ES_MORTAL', 'count'),\n",
    "    Probabilidad_Mortal=('ES_MORTAL', 'mean')\n",
    ").reset_index().to_json('../data/processed/stats_riesgo_meteo.json', orient='records')\n",
    "\n",
    "# 4. Top 20 Carreteras (Puntos Negros)\n",
    "df_historico.groupby('CARRETERA').agg(\n",
    "    Total_Accidentes=('ES_MORTAL', 'count'),\n",
    "    Total_Muertos=('TOTAL_MU24H', 'sum'),\n",
    "    Riesgo_Tramo=('ES_MORTAL', 'mean')\n",
    ").reset_index().sort_values(by='Total_Accidentes', ascending=False).head(20).to_json('../data/processed/stats_riesgo_carreteras.json', orient='records')\n",
    "\n",
    "# 5. Tipolog√≠a de Accidente de Moto\n",
    "df_historico.groupby('TIPO_ACCIDENTE_NOMBRE').agg(\n",
    "    Frecuencia=('ES_MORTAL', 'count'),\n",
    "    Mortalidad_Media=('ES_MORTAL', 'mean')\n",
    ").reset_index().to_json('../data/processed/stats_motos_tipologia.json', orient='records')\n",
    "\n",
    "print(\"üöÄ Todos los JSONs estrat√©gicos han sido generados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtramos accidentes donde hubo al menos un motorista fallecido o implicado\n",
    "# (Usamos MUERTOS_MOTO > 0 para ver letalidad espec√≠fica)\n",
    "df_motos = df_historico[df_historico['MUERTOS_MOTO'] > 0].copy()\n",
    "\n",
    "# 2. Agrupamos por tipo de accidente\n",
    "stats_motos = df_historico.groupby('TIPO_ACCIDENTE_NOMBRE').agg(\n",
    "    Frecuencia=('ES_MORTAL', 'count'),      # Cu√°ntos accidentes de este tipo hay\n",
    "    Tasa_Mortalidad=('ES_MORTAL', 'mean')   # Probabilidad de que sea mortal\n",
    ").reset_index()\n",
    "\n",
    "# Filtramos tipos con muy pocos casos para que la gr√°fica no sea un caos\n",
    "stats_motos = stats_motos[stats_motos['Frecuencia'] > 20]\n",
    "\n",
    "stats_motos.to_json('../data/processed/stats_motos_tipologia.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_provincias = df_historico.groupby('PROVINCIA').agg(\n",
    "    Total_Accidentes=('ES_MORTAL', 'count'),\n",
    "    Muertos_Moto=('MUERTOS_MOTO', 'sum'),\n",
    "    Riesgo_Medio=('ES_MORTAL', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "stats_provincias.to_json('../data/processed/stats_provincias.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_meses = df_historico.groupby('MES').agg(\n",
    "    Muertos_Moto=('MUERTOS_MOTO', 'sum'),\n",
    "    Muertos_Coche=('MUERTOS_COCHE', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "stats_meses.to_json('../data/processed/stats_meses.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Entrenando modelo avanzado XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ELOY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:21:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìä ESTAD√çSTICAS DEL MODELO V2\n",
      "========================================\n",
      "‚úÖ Precisi√≥n General: 0.8626\n",
      "\n",
      "üìù Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93     91502\n",
      "           1       0.05      0.49      0.09      1306\n",
      "\n",
      "    accuracy                           0.86     92808\n",
      "   macro avg       0.52      0.68      0.51     92808\n",
      "weighted avg       0.98      0.86      0.91     92808\n",
      "\n",
      "\n",
      "üîç TOP 5 FACTORES DETERMINANTES:\n",
      "1. TIPO_VIA_NOMBRE: 0.3324\n",
      "2. TIPO_ACCIDENTE_NOMBRE: 0.1908\n",
      "3. ES_NOCTURNO: 0.0808\n",
      "4. CONDICION_ILUMINACION: 0.0744\n",
      "5. PROVINCIA: 0.0668\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- 1. FEATURE ENGINEERING (Mejora de datos) ---\n",
    "def crear_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # A. Variable Fin de Semana mejorada\n",
    "    # Si DIA_SEMANA son n√∫meros (1=Lunes...7=Domingo), el fin de semana es 6 y 7\n",
    "    # Si son strings, buscamos las palabras.\n",
    "    if pd.api.types.is_numeric_dtype(df['DIA_SEMANA']):\n",
    "        df['ES_FIN_SEMANA'] = df['DIA_SEMANA'].isin([6, 7]).astype(int)\n",
    "    else:\n",
    "        dias_festivos = ['S√ÅBADO', 'DOMINGO', 'SABADO']\n",
    "        df['ES_FIN_SEMANA'] = df['DIA_SEMANA'].str.upper().isin(dias_festivos).astype(int)\n",
    "    \n",
    "    # B. Variable Nocturna\n",
    "    df['ES_NOCTURNO'] = ((df['HORA'] >= 22) | (df['HORA'] <= 6)).astype(int)\n",
    "    \n",
    "    # C. Variable Riesgo Visibilidad\n",
    "    # Aseguramos que tratamos con strings para evitar errores similares\n",
    "    meteo_mala = ['LLUVIA', 'NIEVE', 'GRANIZO']\n",
    "    cond_meteo = df['CONDICION_METEO'].astype(str).str.upper()\n",
    "    cond_ilum = df['CONDICION_ILUMINACION'].astype(str).str.upper()\n",
    "    \n",
    "    df['RIESGO_VISIBILIDAD'] = ((cond_meteo.isin(meteo_mala)) & \n",
    "                                (cond_ilum != 'PLENO D√çA')).astype(int)\n",
    "    return df\n",
    "\n",
    "df_enriquecido = crear_features(df_historico)\n",
    "\n",
    "# --- 2. DEFINICI√ìN DE VARIABLES ---\n",
    "features = [\n",
    "    'HORA', 'MES', 'DIA_SEMANA', 'PROVINCIA', 'TIPO_VIA_NOMBRE', \n",
    "    'TIPO_ACCIDENTE_NOMBRE', 'CONDICION_METEO', 'CARRETERA', \n",
    "    'CONDICION_ILUMINACION', 'ES_FIN_SEMANA', 'ES_NOCTURNO', 'RIESGO_VISIBILIDAD'\n",
    "]\n",
    "\n",
    "X = df_enriquecido[features]\n",
    "y = df_enriquecido['ES_MORTAL']\n",
    "\n",
    "categorical_features = [\n",
    "    'DIA_SEMANA', 'PROVINCIA', 'TIPO_VIA_NOMBRE', \n",
    "    'TIPO_ACCIDENTE_NOMBRE', 'CONDICION_METEO', \n",
    "    'CARRETERA', 'CONDICION_ILUMINACION'\n",
    "]\n",
    "\n",
    "# --- 3. PIPELINE CON XGBOOST (M√°s potente que RandomForest) ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "modelo_vial_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=(len(y) - sum(y)) / sum(y), # Balanceo autom√°tico\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- 4. ENTRENAMIENTO ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"üß† Entrenando modelo avanzado XGBoost...\")\n",
    "modelo_vial_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- 5. GUARDAR Y MOSTRAR STATS ---\n",
    "joblib.dump(modelo_vial_pipeline, '../data/processed/modelo_vial_v2.pkl')\n",
    "\n",
    "# M√©tricas detalladas\n",
    "y_pred = modelo_vial_pipeline.predict(X_test)\n",
    "accuracy = modelo_vial_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üìä ESTAD√çSTICAS DEL MODELO V2\")\n",
    "print(\"=\"*40)\n",
    "print(f\"‚úÖ Precisi√≥n General: {accuracy:.4f}\")\n",
    "print(\"\\nüìù Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importancia de las variables (¬øQu√© influye m√°s?)\n",
    "importances = modelo_vial_pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_names = categorical_features + ['HORA', 'MES', 'ES_FIN_SEMANA', 'ES_NOCTURNO', 'RIESGO_VISIBILIDAD']\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\nüîç TOP 5 FACTORES DETERMINANTES:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {feature_names[sorted_idx[i]]}: {importances[sorted_idx[i]]:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Informe de Rendimiento del Modelo Predictivo (v2 - XGBoost)\n",
    "\n",
    "Tras procesar el hist√≥rico de accidentes (2020-2024) y aplicar t√©cnicas de **Feature Engineering**, el modelo ha sido optimizado utilizando un algoritmo de **Extreme Gradient Boosting (XGBoost)**.\n",
    "\n",
    "### üìà M√©tricas de Clasificaci√≥n\n",
    "* **Precisi√≥n General (Accuracy):** `86.26%`\n",
    "* **Recall (Clase Mortal):** `0.49` \n",
    "    > *Nota: El modelo prioriza la detecci√≥n de riesgos (Sensibilidad) sobre la precisi√≥n pura, logrando identificar casi el 50% de los eventos mortales en un dataset altamente desbalanceado.*\n",
    "\n",
    "### üîç Factores Determinantes (Feature Importance)\n",
    "El modelo ha identificado los siguientes factores como los m√°s influyentes en la probabilidad de mortalidad de un accidente:\n",
    "\n",
    "| Ranking | Variable | Peso (Importancia) | Descripci√≥n |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| 1¬∫ | **TIPO_VIA_NOMBRE** | **33.24%** | El dise√±o y velocidad de la v√≠a es el factor cr√≠tico. |\n",
    "| 2¬∫ | **TIPO_ACCIDENTE_NOMBRE** | **19.08%** | La din√°mica del impacto (choque, salida de v√≠a, etc.). |\n",
    "| 3¬∫ | **ES_NOCTURNO** | **8.08%** | Variable creada (Feature Eng.) que confirma el riesgo entre 22:00 y 06:00. |\n",
    "| 4¬∫ | **CONDICION_ILUM** | **7.44%** | La visibilidad artificial o natural en el momento del siniestro. |\n",
    "| 5¬∫ | **PROVINCIA** | **6.68%** | El factor geogr√°fico y de gesti√≥n de infraestructuras locales. |\n",
    "\n",
    "\n",
    "\n",
    "### üõ†Ô∏è Mejoras Implementadas\n",
    "1.  **Ingenier√≠a de Variables:** Creaci√≥n de indicadores sint√©ticos como `ES_NOCTURNO` (franja horaria de riesgo) y `RIESGO_VISIBILIDAD` (cruce de meteorolog√≠a e iluminaci√≥n).\n",
    "2.  **Tratamiento de Desbalanceo:** Implementaci√≥n de `scale_pos_weight` para ajustar el aprendizaje ante la baja frecuencia de accidentes mortales.\n",
    "3.  **Normalizaci√≥n:** Pipeline automatizado para la codificaci√≥n de variables categ√≥ricas y gesti√≥n de valores desconocidos.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
